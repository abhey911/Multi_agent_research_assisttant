# Multi-Agent Research Assistant ğŸ¤–

An intelligent research system powered by multiple specialized AI agents that collaborate to research topics, analyze information, synthesize findings, and produce comprehensive research reports.

## ğŸŒŸ Features

- **Multi-Agent Collaboration**: Specialized agents work together (Researcher, Analyzer, Writer, Critic)
- **Autonomous Research**: Agents independently gather and process information
- **Quality Assurance**: Built-in review and revision cycle
- **Interactive UI**: User-friendly Streamlit web interface
- **Comprehensive Reports**: Well-structured, properly cited research documents
- **Customizable**: Adjustable research depth and configuration

## ğŸ—ï¸ Architecture

The system uses four specialized agents:

1. **ğŸ” Researcher Agent**: Gathers information from web sources
2. **ğŸ“Š Analyzer Agent**: Processes data and extracts insights
3. **âœï¸ Writer Agent**: Creates comprehensive research reports
4. **ğŸ” Critic Agent**: Reviews and ensures quality

## ğŸ“‹ Prerequisites

- Python 3.8 or higher
- Google Gemini API key
- Internet connection for web searches

## ğŸš€ Installation

### 1. Clone or Download the Repository

```bash
cd multi-agent-research
```

### 2. Create Virtual Environment

**Windows (PowerShell):**
```powershell
python -m venv venv
venv\Scripts\Activate.ps1
```

**Windows (Command Prompt):**
```cmd
python -m venv venv
venv\Scripts\activate.bat
```

**Linux/Mac:**
```bash
python -m venv venv
source venv/bin/activate
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

### 4. Configure Environment Variables

1. Copy the example environment file:
   ```bash
   cp .env.example .env
   ```
   
2. Edit `.env` and add your API keys:
   ```env
   GOOGLE_API_KEY=your_google_gemini_api_key_here
   SERPAPI_API_KEY=your_serpapi_key_here  # Optional
   ```

To get a Google Gemini API key:
- Visit: https://makersuite.google.com/app/apikey
- Sign in with your Google account
- Create a new API key
- Copy and paste it into your `.env` file

## ğŸ’» Usage

### Running the Application

Start the Streamlit web interface:

```bash
streamlit run streamlit_app.py
```

The application will open in your default web browser at `http://localhost:8501`

### Using the Interface

1. **Enter Research Topic**: Type your research query in the text area
2. **Select Research Depth**: Choose between Quick, Standard, or Deep
3. **Start Research**: Click the "Start Research" button
4. **Monitor Progress**: Watch the agent progress indicators
5. **View Report**: Read the generated research report
6. **Download/Copy**: Save or copy the report as needed

### Example Research Topics

- "Current state of quantum computing and its applications in cryptography"
- "Impact of artificial intelligence on healthcare diagnostics"
- "Renewable energy technologies and their economic viability"
- "Evolution of blockchain technology beyond cryptocurrency"
- "Latest developments in gene therapy and CRISPR technology"

## ğŸ“ Project Structure

```
multi-agent-research/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/              # Agent implementations
â”‚   â”‚   â”œâ”€â”€ researcher.py    # Research agent
â”‚   â”‚   â”œâ”€â”€ analyzer.py      # Analysis agent
â”‚   â”‚   â”œâ”€â”€ writer.py        # Writing agent
â”‚   â”‚   â””â”€â”€ critic.py        # Review agent
â”‚   â”œâ”€â”€ tools/               # Agent tools
â”‚   â”‚   â”œâ”€â”€ search_tool.py   # Web search functionality
â”‚   â”‚   â”œâ”€â”€ scraping_tool.py # Web scraping functionality
â”‚   â”‚   â””â”€â”€ processing_tool.py # Data processing
â”‚   â”œâ”€â”€ tasks/               # Task definitions
â”‚   â”‚   â””â”€â”€ research_tasks.py # Research workflow tasks
â”‚   â””â”€â”€ utils/               # Utility functions
â”‚       â”œâ”€â”€ config.py        # Configuration management
â”‚       â””â”€â”€ helpers.py       # Helper functions
â”œâ”€â”€ config/
â”‚   â””â”€â”€ agents_config.yaml   # Agent and task configurations
â”œâ”€â”€ outputs/
â”‚   â””â”€â”€ reports/             # Generated research reports
â”œâ”€â”€ streamlit_app.py         # Main application
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ .env.example             # Environment variables template
â””â”€â”€ README.md                # This file
```

## âš™ï¸ Configuration

### Agent Configuration

Modify `config/agents_config.yaml` to customize agent behavior:

```yaml
agents:
  researcher:
    role: "Research Specialist"
    goal: "Gather comprehensive information on {topic}"
    max_iterations: 10
  # ... other agents
```

### Environment Variables

Available configuration options in `.env`:

```env
# Required
GOOGLE_API_KEY=your_key_here

# Optional
SERPAPI_API_KEY=your_key_here
MAX_SEARCH_RESULTS=10
MAX_ITERATIONS=5
RESEARCH_DEPTH=standard
```

## ğŸ› ï¸ Troubleshooting

### Common Issues

**1. ModuleNotFoundError**
```bash
# Ensure virtual environment is activated and dependencies are installed
pip install -r requirements.txt
```

**2. API Key Errors**
- Verify your `.env` file exists and contains valid API keys
- Check that GOOGLE_API_KEY is set correctly

**3. Search Tool Issues**
- The system uses DuckDuckGo by default (no API key needed)
- For Google search, add SERPAPI_API_KEY to your `.env`

**4. Slow Performance**
- Research can take 3-5 minutes depending on topic complexity
- Reduce MAX_SEARCH_RESULTS in `.env` for faster results

## ğŸ“Š How It Works

### Workflow

1. **User Input** â†’ Research topic submitted
2. **Manager** â†’ Coordinates agent workflow
3. **Researcher** â†’ Searches web and gathers information
4. **Analyzer** â†’ Processes findings and extracts insights
5. **Writer** â†’ Creates structured research report
6. **Critic** â†’ Reviews quality and suggests improvements
7. **Output** â†’ Final polished research report

### Agent Communication

Agents communicate through a sequential workflow where each agent's output becomes the input for the next:

```
Researcher â†’ Analyzer â†’ Writer â†’ Critic
   â†“            â†“         â†“         â†“
Sources â†’ Insights â†’ Draft â†’ Review â†’ Final Report
```

## ğŸ¯ Use Cases

- **Academic Research**: Literature reviews, topic summaries
- **Market Research**: Industry analysis, competitor research
- **Technical Documentation**: Technology assessments, feasibility studies
- **Due Diligence**: Company research, risk analysis
- **Content Creation**: In-depth articles, white papers
- **Learning**: Study guides, topic explorations

## ğŸ”’ Privacy & Security

- All processing happens locally except API calls to Google Gemini
- No data is stored or transmitted to third parties
- Reports are saved locally in the `outputs/reports` directory
- API keys are stored in `.env` (never commit this file)

## ğŸ¤ Contributing

Contributions are welcome! Areas for improvement:

- Additional search tools and data sources
- Parallel agent execution
- Enhanced UI features
- Custom report templates
- Multi-language support

## ğŸ“ License

This project is provided as-is for educational and research purposes.

## ğŸ™ Acknowledgments

Built with:
- [CrewAI](https://github.com/joaomdmoura/crewAI) - Multi-agent framework
- [Google Gemini](https://deepmind.google/technologies/gemini/) - Language models
- [Streamlit](https://streamlit.io/) - Web interface
- [LangChain](https://www.langchain.com/) - LLM framework

## ğŸ“§ Support

For issues and questions:
1. Check the troubleshooting section
2. Review configuration files
3. Ensure all dependencies are installed
4. Verify API keys are valid

## ğŸ”„ Version History

- **v1.0.0** (December 2025) - Initial release
  - Multi-agent research system
  - Streamlit web interface
  - Google Gemini integration
  - Web search and scraping tools

---

**Happy Researching! ğŸš€**
